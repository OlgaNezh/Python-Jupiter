{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Урок 3. Построение модели классификации.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варианты усреднения метрик качества особенно полезны для решения задач многоклассовой классификации. Самый простой и стандардтный вариант - это macro. В нем берутся усредненные значения для каждого из классов. Macro не делает различий между более и менее важными классами. Также, macro фокусируется на распозновании класса, а не усредненных значениях precision/recall для всей модели. Micro вариант усредняет precision/recall для всей многоклассовой модели, но не уделяет внимания распределению классов в данных. Weighted вариант присваивает веса для каждого из классов, исходя из их распределения в данных.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost - это eXtreme Gradient Boosting, т.е. в основе данной модели лежит градиентный бустинг. XGBoost посчитывает похожеть между элементами и производит стрижку результирующих деревьев, основываясь на гиперпараметр гамма. Прирост информации в XGBoost подсчитывается, как разница между суммой веток и вершины.\n",
    "LightGBM - это облегченная версия градиентного бустинга, которая заостряет внимание на ошибках и не использует всю выборку. Также, эта модель группирует разреженные признаки, типичные для бинарного формата машинного обучения, а также признаки с близкими диапазонами значений.\n",
    "Catboost - это быстрая модель градиентного бустинга, построенная на симметричных разветвлениях. Выдерживая симметрию, модель решает проблемы классификации быстрее аналогов. В дополнение, эта модель сама переводит признаки в нужный формат без использования функции get_dummies и имеет встроенные алгоритмы, препятствующие переобучению.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
